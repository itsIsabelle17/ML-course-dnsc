{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvt2EhcNamhm"
      },
      "source": [
        "# MNIST Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Imports"
      ],
      "metadata": {
        "id": "-Lzerk-SbfmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras # overall package API for deep learning\n",
        "\n",
        "# for data loading/prep\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# for training\n",
        "from keras.models import Sequential # for building sequential, not recurrent, networks\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense # for the components of a lenet5-like network"
      ],
      "metadata": {
        "id": "tm_GcmscbT9w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Try for reproducibility"
      ],
      "metadata": {
        "id": "aIy6L5Wyj61Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONHASHSEED=0"
      ],
      "metadata": {
        "id": "Th0bp1ehj9rE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "SEED = 12345\n",
        "\n",
        "np.random.seed(SEED)\n",
        "python_random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "2JaLb5UEkG-U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load and format MNIST data"
      ],
      "metadata": {
        "id": "N7b_uvmPbi8J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9iqzI6e-amhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccf02c1-3f47-4497-cb70-68db170b87b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
        "\n",
        "# normalize data \n",
        "x_train = x_train/255\n",
        "x_valid = x_valid/255\n",
        "\n",
        "# ensure y's are treated as categories\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_valid = np_utils.to_categorical(y_valid)\n",
        "num_classes = y_train.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Examine data"
      ],
      "metadata": {
        "id": "wRbr2s--cTOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array2string(x_train[0], max_line_width=150, precision=2)) # pixel intensities for first training image\n",
        "print()\n",
        "print(y_train[0]) # label for first training image"
      ],
      "metadata": {
        "id": "u7TrwHdCcWbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78daabea-73ca-4f5f-816f-32fdc442b3f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.07 0.07 0.07 0.49 0.53 0.69 0.1  0.65 1.   0.97 0.5  0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.12 0.14 0.37 0.6  0.67 0.99 0.99 0.99 0.99 0.99 0.88 0.67 0.99 0.95 0.76 0.25 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.19 0.93 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.99 0.98 0.36 0.32 0.32 0.22 0.15 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.07 0.86 0.99 0.99 0.99 0.99 0.99 0.78 0.71 0.97 0.95 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.31 0.61 0.42 0.99 0.99 0.8  0.04 0.   0.17 0.6  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.05 0.   0.6  0.99 0.35 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.55 0.99 0.75 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.04 0.75 0.99 0.27 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.14 0.95 0.88 0.63 0.42 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.32 0.94 0.99 0.99 0.47 0.1  0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.18 0.73 0.99 0.99 0.59 0.11 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.06 0.36 0.99 0.99 0.73 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.98 0.99 0.98 0.25 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.18 0.51 0.72 0.99 0.99 0.81 0.01 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.15 0.58 0.9  0.99 0.99 0.99 0.98 0.71 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.09 0.45 0.87 0.99 0.99 0.99 0.99 0.79 0.31 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.09 0.26 0.84 0.99 0.99 0.99 0.99 0.78 0.32 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.07 0.67 0.86 0.99 0.99 0.99 0.99 0.76 0.31 0.04 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.22 0.67 0.89 0.99 0.99 0.99 0.99 0.96 0.52 0.04 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.53 0.99 0.99 0.99 0.83 0.53 0.52 0.06 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXwuqWrbamhw"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Initialize a sequential Keras model"
      ],
      "metadata": {
        "id": "VlXB4wbme5nW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "id": "X5lU_49Bamhy"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define a smaller version of Lenet-5 that uses the standard 28x28 MNIST images"
      ],
      "metadata": {
        "id": "7ytM8PHnfKOf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": false,
        "id": "TCNU40zmamhy"
      },
      "outputs": [],
      "source": [
        "from keras.backend import tanh\n",
        "from keras.activations import sigmoid\n",
        "# C1\n",
        "# 1 image in, 6 feature maps out (1 image represented *in each of* the 6 feature maps)\n",
        "# 28 x 28 x 1 inputs\n",
        "# 1 image goes into 6 filters with (1 x 2 x 2 + 1) = 5 weights for 30 total weights in C1 layer\n",
        "# resulting in ((28 - 2 + 0)/1) + 1 = 27 x 27 x 6 output volume\n",
        "model.add(Conv2D(filters=6, kernel_size=(2,2), input_shape=(28,28,1)))\n",
        "\n",
        "# S2\n",
        "# 6 feature maps in, 6 activation maps out\n",
        "# 27 x 27 x 6 input volume \n",
        "# goes into 0 weights in S2 layer\n",
        "# pooling implies kernel size 4, stride 2 and padding of 0.5 b/c of odd input size\n",
        "# resulting in a ((27 - 4 + 1)/2) + 1 = 13 x 13 x 6 output volume\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "model.add(Activation('sigmoid')) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# C3\n",
        "# 6 activation maps in, 16 feature maps out (6 activation maps represented *in each of* the 16 feature maps)\n",
        "# 13 x 13 x 6 input volume\n",
        "# 6 activation maps go into 16 filters with (6 x 5 x 5 + 1) = 151 weights for a total of 2416 weights in C3 layer\n",
        "# resulting in ((13 - 5 + 0)/1) + 1 = 9 x 9 x 16 output volume\n",
        "model.add(Conv2D(filters=16, kernel_size=(5,5)))\n",
        "\n",
        "# S4\n",
        "# 16 feature maps in, 16 activation maps out\n",
        "# 9 x 9 x 16 input volume\n",
        "# goes into 0 weights in S2 layer\n",
        "# pooling implies kernel size 4, stride 2 and padding of 0.5 b/c of odd input size\n",
        "# resulting in (9 - 4 + 1)/2) + 1 = 4 x 4 x 16 output volume\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Activation('sigmoid')) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# C5\n",
        "# 16 activation maps in, 120 feature maps out (16 activation maps represented *in each of* the 120 feature maps)\n",
        "# 4 x 4 16 input volume\n",
        "# 16 activation maps go into 120 filters with (16 x 4 x 4 + 1) = 257 weights for a total of 30,840 weights in C5 layer\n",
        "# resulting in a  (4 - 4 + 0)/1) + 1 = 1 x 1 x 120 output volume \n",
        "model.add(Conv2D(filters=120, kernel_size=(4,4))) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# F6\n",
        "# 120 input elements are flattened and connected to 84 weights with biases\n",
        "# resulting in a 120 x 84 + 84 = 10,164 weights in F6 and a 84 x 1 x 1 output volume\n",
        "model.add(Flatten())\n",
        "model.add(Dense(84)) # REQUIRES STUDENT INPUT\n",
        "model.add(Activation('tanh')) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# Output\n",
        "# each of 84 units in F6 feed into 10 softmax output units\n",
        "# there are 84 x 10 + 10 = 850 weights in the output layer resulting in a 10 x 1 x 1 output volume\n",
        "# output unit with highest output \"probability\" is the prediction for the image\n",
        "model.add(Dense(10)) # REQUIRES STUDENT INPUT\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. View a summary of the model architecture"
      ],
      "metadata": {
        "id": "F-wrQbwKgz7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nADiLqGhg40-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2b8c5d-371a-4322-b8fc-78de9c5d8a60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 27, 27, 6)         30        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " activation (Activation)     (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 9, 9, 16)          2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4, 4, 16)          0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 1, 1, 120)         30840     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 120)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,300\n",
            "Trainable params: 44,300\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Precompile model for faster training"
      ],
      "metadata": {
        "id": "SOHpwRpzg87f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zah-mHZdamhz"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Train model"
      ],
      "metadata": {
        "id": "tRAEx-j2hS3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iHaLygfzamh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece1f81f-888c-4354-c34b-d0ae6c16fba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 2.3039 - accuracy: 0.1107\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 2.2985 - accuracy: 0.1192\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 2.2927 - accuracy: 0.1353\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 2.2810 - accuracy: 0.1590\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 2.2510 - accuracy: 0.2297\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 2.1295 - accuracy: 0.4050\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 1.5834 - accuracy: 0.6136\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.9147 - accuracy: 0.7585\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.6471 - accuracy: 0.8202\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.5311 - accuracy: 0.8495\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.4636 - accuracy: 0.8666\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.4168 - accuracy: 0.8798\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.3822 - accuracy: 0.8888\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.3542 - accuracy: 0.8958\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.3316 - accuracy: 0.9025\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.3116 - accuracy: 0.9075\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.2950 - accuracy: 0.9120\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.2795 - accuracy: 0.9169\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.2656 - accuracy: 0.9212\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.2533 - accuracy: 0.9244\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.2420 - accuracy: 0.9278\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.2311 - accuracy: 0.9306\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.2211 - accuracy: 0.9342\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.2119 - accuracy: 0.9366\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.2038 - accuracy: 0.9388\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.1961 - accuracy: 0.9413\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1888 - accuracy: 0.9433\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.1822 - accuracy: 0.9447\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.1762 - accuracy: 0.9472\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.1704 - accuracy: 0.9488\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.1651 - accuracy: 0.9507\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.1602 - accuracy: 0.9527\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.1557 - accuracy: 0.9535\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1514 - accuracy: 0.9546\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1474 - accuracy: 0.9557\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1436 - accuracy: 0.9571\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1402 - accuracy: 0.9579\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1367 - accuracy: 0.9591\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 0.1338 - accuracy: 0.9600\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 0.1306 - accuracy: 0.9610\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1280 - accuracy: 0.9615\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1253 - accuracy: 0.9626\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1229 - accuracy: 0.9629\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1202 - accuracy: 0.9639\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1181 - accuracy: 0.9645\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 0.1158 - accuracy: 0.9654\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1138 - accuracy: 0.9655\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1119 - accuracy: 0.9661\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1099 - accuracy: 0.9663\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 0.1082 - accuracy: 0.9669\n"
          ]
        }
      ],
      "source": [
        "# restart and run notebook for reproducible results\n",
        "# running this cell multiple times will result in irreproducible results\n",
        "_ = model.fit(x_train, y_train, epochs=50, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Evaluate model performance on validation data"
      ],
      "metadata": {
        "id": "diOlWRfXiDi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lW1I2J0samh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45411de3-f0f5-46df-9d20-6f6758f28378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 17ms/step - loss: 0.0981 - accuracy: 0.9702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09812403470277786, 0.9702000021934509]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.evaluate(x_valid, y_valid, batch_size=128)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Assignment_8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}